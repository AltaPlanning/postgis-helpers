{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from a variety of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pGIS --> Creating database: example_database on localhost\n         ... executing ...\n         \t CREATE DATABASE example_database;\n         \t Runtime: 0:00:00.059\n         Installing PostGIS\n         ... executing ...\n         \t CREATE EXTENSION postgis;\n         \t Runtime: 0:00:01.972\n         Installing custom hexagon grid function\n         ... executing ...\n         \t Runtime: 0:00:00.006\npGIS --> example_database @ localhost\n"
    }
   ],
   "source": [
    "# Import the module and connect to / create a new PostgreSQL database\n",
    "\n",
    "import postgis_helpers as pGIS\n",
    "\n",
    "db = pGIS.PostgreSQL(\"example_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a shapefile that you've downloaded locally\n",
    "\n",
    "Download the shapefile referenced below [from here](https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+high_injury_network_2017&filename=high_injury_network_2017&format=shp&skipfields=cartodb_id).\n",
    "\n",
    "Windows users will need to manually extract the downloaded ZIP file. If you're on a Mac it will automatically extract itself.\n",
    "\n",
    "There are two methods for importing geodata:\n",
    "\n",
    "``db.import_geodata()`` and ``db.shp2pgsql()``. The former utilizes ``geopandas``, while the latter executes a ``shp2pgsql`` command on the system's terminal. This will only work if the path to ``psql`` is set up approriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pGIS --> Loading spatial data to geodataframe\npGIS --> Importing LINESTRING geodataframe to: loaded_via_geopandas\n         Adding uid column to loaded_via_geopandas\n         ... executing ...\n         \t \n            ALTER TABLE loaded_via_geopandas DROP COLUMN IF EXISTS uid;\n            ALTER TABLE loaded_via_geopandas ADD uid serial PRIMARY KEY;\n        \n         \t Runtime: 0:00:00.025\n         Creating a spatial index on loaded_via_geopandas\n         ... executing ...\n         \t \n            DROP INDEX IF EXISTS gix_loaded_via_geopandas;\n            CREATE INDEX gix_loaded_via_geopandas\n            ON loaded_via_geopandas\n            USING GIST (geom);\n        \n         \t Runtime: 0:00:00.014\n"
    }
   ],
   "source": [
    "local_shapefile = \"/Users/aaron/Downloads/high_injury_network_2017/high_injury_network_2017.shp\"\n",
    "\n",
    "db.import_geodata(\"loaded_via_geopandas\", local_shapefile, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'shp2pgsql -d -e -I -S -s 4326 /Users/aaron/Downloads/high_injury_network_2017/high_injury_network_2017 loaded_via_shp2pgsql | psql postgresql://postgres:password1@localhost:5432/example_database'"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "db.shp2pgsql(\"loaded_via_shp2pgsql\", local_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'loaded_via_geopandas': 4326, 'loaded_via_shp2pgsql': 4326}"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "db.all_spatial_tables_as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CSV files\n",
    "\n",
    "The ``db.import_csv()`` function return a dataframe of what was imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pGIS --> Loading CSV to dataframe\npGIS --> Importing dataframe to: csv_imported_via_pandas\n         \t Runtime: 0:00:00.194\nImported table has 58 rows and 18 cols\n"
    }
   ],
   "source": [
    "csv_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/06-10-2020.csv\"\n",
    "\n",
    "\n",
    "df = db.import_csv(\"csv_imported_via_pandas\", csv_url)\n",
    "\n",
    "rows, cols = df.shape\n",
    "print(f\"Imported table has {rows} rows and {cols} cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['geography_columns',\n 'geometry_columns',\n 'spatial_ref_sys',\n 'loaded_via_geopandas',\n 'loaded_via_shp2pgsql',\n 'csv_imported_via_pandas']"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "db.all_tables_as_list()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitpostgishelpersconda12ea1a6fc9c04b618d5ef9289b1490f5",
   "display_name": "Python 3.8.3 64-bit ('postgis_helpers': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}